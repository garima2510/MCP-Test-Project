{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18ff6a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../mcp_project/mcp_chatbot_azure.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../mcp_project/mcp_chatbot_azure.py\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "from mcp import ClientSession, StdioServerParameters, types\n",
    "from mcp.client.stdio import stdio_client\n",
    "from typing import List\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "import json\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "class MCP_ChatBot:\n",
    "\n",
    "    def __init__(self):\n",
    "        # Initialize session and client objects\n",
    "        self.session: ClientSession = None\n",
    "        \n",
    "        # Initialize Azure OpenAI client\n",
    "        self.client = AzureOpenAI(\n",
    "            api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "            api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\", \"2024-02-15-preview\"),\n",
    "            azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "        )\n",
    "        \n",
    "        self.deployment_name = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\", \"gpt-4\")\n",
    "        self.available_tools: List[dict] = []\n",
    "\n",
    "    def convert_mcp_tools_to_openai_format(self, mcp_tools):\n",
    "        \"\"\"Convert MCP tool format to OpenAI function calling format\"\"\"\n",
    "        openai_functions = []\n",
    "        for tool in mcp_tools:\n",
    "            function_def = {\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": tool[\"name\"],\n",
    "                    \"description\": tool[\"description\"],\n",
    "                    \"parameters\": tool[\"input_schema\"]\n",
    "                }\n",
    "            }\n",
    "            openai_functions.append(function_def)\n",
    "        return openai_functions\n",
    "\n",
    "    async def process_query(self, query):\n",
    "        messages = [{'role': 'user', 'content': query}]\n",
    "        \n",
    "        # Convert MCP tools to OpenAI format\n",
    "        openai_tools = self.convert_mcp_tools_to_openai_format(self.available_tools)\n",
    "        \n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.deployment_name,\n",
    "            messages=messages,\n",
    "            tools=openai_tools if openai_tools else None,\n",
    "            tool_choice=\"auto\" if openai_tools else None,\n",
    "            max_tokens=2048\n",
    "        )\n",
    "        \n",
    "        process_query = True\n",
    "        while process_query:\n",
    "            message = response.choices[0].message\n",
    "            \n",
    "            # Handle text response\n",
    "            if message.content:\n",
    "                print(message.content)\n",
    "                messages.append({'role': 'assistant', 'content': message.content})\n",
    "                \n",
    "            # Handle tool calls\n",
    "            if message.tool_calls:\n",
    "                messages.append({\n",
    "                    'role': 'assistant', \n",
    "                    'content': message.content,\n",
    "                    'tool_calls': message.tool_calls\n",
    "                })\n",
    "                \n",
    "                for tool_call in message.tool_calls:\n",
    "                    tool_name = tool_call.function.name\n",
    "                    tool_args = json.loads(tool_call.function.arguments)\n",
    "                    tool_id = tool_call.id\n",
    "                    \n",
    "                    print(f\"Calling tool {tool_name} with args {tool_args}\")\n",
    "                    \n",
    "                    # Call MCP tool through the client session\n",
    "                    try:\n",
    "                        result = await self.session.call_tool(tool_name, arguments=tool_args)\n",
    "                        \n",
    "                        # Convert result to string if it's not already\n",
    "                        if hasattr(result, 'content'):\n",
    "                            result_content = str(result.content)\n",
    "                        else:\n",
    "                            result_content = str(result)\n",
    "                            \n",
    "                        messages.append({\n",
    "                            \"role\": \"tool\",\n",
    "                            \"tool_call_id\": tool_id,\n",
    "                            \"content\": result_content\n",
    "                        })\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"Error calling tool {tool_name}: {e}\")\n",
    "                        messages.append({\n",
    "                            \"role\": \"tool\",\n",
    "                            \"tool_call_id\": tool_id,\n",
    "                            \"content\": f\"Error: {str(e)}\"\n",
    "                        })\n",
    "                \n",
    "                # Get next response from OpenAI\n",
    "                response = self.client.chat.completions.create(\n",
    "                    model=self.deployment_name,\n",
    "                    messages=messages,\n",
    "                    tools=openai_tools if openai_tools else None,\n",
    "                    tool_choice=\"auto\" if openai_tools else None,\n",
    "                    max_tokens=2048\n",
    "                )\n",
    "                \n",
    "            else:\n",
    "                # No more tool calls, we're done\n",
    "                process_query = False\n",
    "\n",
    "    async def chat_loop(self):\n",
    "        \"\"\"Run an interactive chat loop\"\"\"\n",
    "        print(\"\\nMCP Chatbot with Azure OpenAI Started!\")\n",
    "        print(\"Type your queries or 'quit' to exit.\")\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                query = input(\"\\nQuery: \").strip()\n",
    "        \n",
    "                if query.lower() == 'quit':\n",
    "                    break\n",
    "                    \n",
    "                await self.process_query(query)\n",
    "                print(\"\\n\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"\\nError: {str(e)}\")\n",
    "\n",
    "    async def connect_to_server_and_run(self):\n",
    "        # Create server parameters for stdio connection\n",
    "        server_params = StdioServerParameters(\n",
    "            command=\"python\",  # Changed from \"uv\" to \"python\"\n",
    "            args=[\"research_server.py\"],  # Path to your MCP server\n",
    "            env=None,  # Optional environment variables\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            async with stdio_client(server_params) as (read, write):\n",
    "                async with ClientSession(read, write) as session:\n",
    "                    self.session = session\n",
    "                    # Initialize the connection\n",
    "                    await session.initialize()\n",
    "        \n",
    "                    # List available tools\n",
    "                    response = await session.list_tools()\n",
    "                    \n",
    "                    tools = response.tools\n",
    "                    print(\"\\nConnected to server with tools:\", [tool.name for tool in tools])\n",
    "                    \n",
    "                    self.available_tools = [{\n",
    "                        \"name\": tool.name,\n",
    "                        \"description\": tool.description,\n",
    "                        \"input_schema\": tool.inputSchema\n",
    "                    } for tool in response.tools]\n",
    "        \n",
    "                    await self.chat_loop()\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Error connecting to MCP server: {e}\")\n",
    "            print(\"Make sure your MCP server is working and the path is correct.\")\n",
    "\n",
    "async def main():\n",
    "    chatbot = MCP_ChatBot()\n",
    "    await chatbot.connect_to_server_and_run()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55032ac",
   "metadata": {},
   "source": [
    "To run the client, use `python mcp_chatbot_azure.py`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
